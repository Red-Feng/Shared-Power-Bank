{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "警告: sklearn 导入失败 (The `scipy` install you are using seems to be broken, (extension modules cannot be imported), please try reinstalling.)，将使用手动实现的 train_test_split\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "# 尝试导入 sklearn，如果失败则使用手动实现\n",
    "try:\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    USE_SKLEARN = True\n",
    "except ImportError as e:\n",
    "    print(f\"警告: sklearn 导入失败 ({e})，将使用手动实现的 train_test_split\")\n",
    "    USE_SKLEARN = False\n",
    "    \n",
    "    def train_test_split(X, y, test_size=0.2, random_state=None):\n",
    "        \"\"\"手动实现的 train_test_split，不依赖 sklearn\"\"\"\n",
    "        if random_state is not None:\n",
    "            np.random.seed(random_state)\n",
    "        \n",
    "        n_samples = len(X)\n",
    "        n_test = int(n_samples * test_size)\n",
    "        indices = np.random.permutation(n_samples)\n",
    "        \n",
    "        test_indices = indices[:n_test]\n",
    "        train_indices = indices[n_test:]\n",
    "        \n",
    "        X_train, X_test = X[train_indices], X[test_indices]\n",
    "        y_train, y_test = y[train_indices], y[test_indices]\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "def extract_numeric_features(data):\n",
    "    feature_columns = ['充放电次数', '环境温度', '当前电量']\n",
    "    numeric_data = pd.DataFrame()\n",
    "\n",
    "    for col in feature_columns:\n",
    "        if col in data.columns:\n",
    "            extracted_values = []\n",
    "            for value in data[col]:\n",
    "                if pd.isna(value):\n",
    "                    extracted_values.append(np.nan)\n",
    "                else:\n",
    "                    matches = re.findall(r'\\d+\\.?\\d*', str(value))\n",
    "                    if matches:\n",
    "                        try:\n",
    "                            extracted_values.append(float(matches[0]))\n",
    "                        except ValueError:\n",
    "                            extracted_values.append(np.nan)\n",
    "                    else:\n",
    "                        extracted_values.append(np.nan)\n",
    "            numeric_data[col] = extracted_values\n",
    "    return numeric_data\n",
    "\n",
    "\n",
    "def load_battery_data(file_path, test_ratio=0.2, random_state=None):\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"Excel文件 {file_path} 不存在\")\n",
    "\n",
    "    try:\n",
    "        data = pd.read_excel(file_path)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"读取Excel文件失败: {str(e)}\")\n",
    "\n",
    "\n",
    "    numeric_features = extract_numeric_features(data)\n",
    "\n",
    "    label_column = '电池量'\n",
    "    y = data[label_column].values\n",
    "\n",
    "    X = numeric_features.values\n",
    "    \n",
    "    # 使用已导入的 train_test_split（可能是 sklearn 或手动实现）\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_ratio, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b042f7064c9ff03",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4425c8d77ca4aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T13:07:16.975882600Z",
     "start_time": "2025-12-19T12:45:09.640782800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1192f1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "class Affine:\n",
    "    def __init__(self,W,b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.x = None\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "    \n",
    "    def forward(self,x):\n",
    "        self.x = x\n",
    "        out = np.dot(x,self.W) + self.b\n",
    "        return out\n",
    "    \n",
    "    def backward(self,dout):\n",
    "        dx = np.dot(dout,self.W.T)\n",
    "        self.dW = np.dot(self.x.T,dout)\n",
    "        self.db = np.sum(dout,axis=0)\n",
    "        return dx\n",
    "    \n",
    "class AddPower:\n",
    "    def __init__(self,exponent):\n",
    "        self.exponent = exponent\n",
    "        self.x = None\n",
    "        self.dExponent = None\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x += 1e-7\n",
    "        self.x = x\n",
    "        out = np.power(x,self.exponent)\n",
    "        return out\n",
    "    \n",
    "    def backward(self,dout):\n",
    "        dx = np.power(self.x,self.exponent-1) * self.exponent * dout\n",
    "        dExponent_full = self.x ** self.exponent * np.log(self.x) * dout\n",
    "        self.dExponent = np.sum(dExponent_full, axis=0)\n",
    "        return dx\n",
    "\n",
    "def mse(y,t):\n",
    "    return np.mean((y-t)**2) * 0.5\n",
    "\n",
    "class MSE:\n",
    "    def __init__(self):\n",
    "        self.loss = None\n",
    "        self.y = None\n",
    "        self.t = None\n",
    "    \n",
    "    def forward(self,y,t):\n",
    "        self.y = y\n",
    "        self.t = t\n",
    "        self.loss = mse(y,t)\n",
    "        return self.loss\n",
    "    \n",
    "    def backward(self,dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        if len(self.t.shape) == 1:\n",
    "            t_reshaped = self.t.reshape(-1, 1)\n",
    "        else:\n",
    "            t_reshaped = self.t\n",
    "        dx = (self.y - t_reshaped) / batch_size\n",
    "        return dx\n",
    "\n",
    "class battery_model:\n",
    "    def __init__(self,input_size=3,output_size=1,weight_init=0.1):\n",
    "        self.params = {}\n",
    "        self.params['exponent'] = np.ones(input_size)\n",
    "        self.params['W1'] = np.random.randn(input_size,output_size) * weight_init\n",
    "        self.params['b1'] = np.zeros(output_size)\n",
    "        \n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['AddPower'] = AddPower(self.params['exponent'])\n",
    "        self.layers['Affine1'] = Affine(self.params['W1'], self.params['b1'])\n",
    "        \n",
    "        self.loss_layer = MSE()\n",
    "        \n",
    "        \n",
    "    def predict(self,x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "    \n",
    "    def loss(self,x,t):\n",
    "        y = self.predict(x)\n",
    "        if len(t.shape) == 1:\n",
    "            t = t.reshape(-1, 1)\n",
    "        return self.loss_layer.forward(y,t)\n",
    "    \n",
    "    def gradient(self,x,t):\n",
    "        if len(t.shape) == 1:\n",
    "            t = t.reshape(-1, 1)\n",
    "        self.loss(x,t)\n",
    "        dout = self.loss_layer.backward()\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "        \n",
    "        gradient = {\n",
    "                'exponent': self.layers['AddPower'].dExponent,\n",
    "                'W1': self.layers['Affine1'].dW,\n",
    "                'b1': self.layers['Affine1'].db\n",
    "        }\n",
    "        \n",
    "        return gradient\n",
    "    \n",
    "    def accuracy(self,x,t,threshold=0.05):\n",
    "        y = self.predict(x)\n",
    "        \n",
    "        if len(t.shape) == 1:\n",
    "            t = t.reshape(-1, 1)\n",
    "\n",
    "        relative_error = np.abs((y - t) / (t + 1e-7))\n",
    "\n",
    "        correct = relative_error <= threshold\n",
    "        return np.mean(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f74b7f93dad23896",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T13:07:16.976882900Z",
     "start_time": "2025-12-19T12:45:09.648105100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def batch_train(model, X_train, y_train, X_test=None, y_test=None, epochs=10, batch_size=100, learning_rate=0.01, verbose=True):\n",
    "\n",
    "    num_samples = X_train.shape[0]\n",
    "    num_batches = num_samples // batch_size\n",
    "    \n",
    "    if num_samples % batch_size != 0:\n",
    "        num_batches += 1\n",
    "        \n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'test_loss': [],\n",
    "        'train_accuracy': [],\n",
    "        'test_accuracy': []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        indices = np.random.permutation(num_samples)\n",
    "        X_train_shuffled = X_train[indices]\n",
    "        y_train_shuffled = y_train[indices]\n",
    "        \n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for i in range(num_batches):\n",
    "            start_idx = i * batch_size\n",
    "            end_idx = min((i + 1) * batch_size, num_samples)\n",
    "            \n",
    "            X_batch = X_train_shuffled[start_idx:end_idx]\n",
    "            y_batch = y_train_shuffled[start_idx:end_idx]\n",
    "            \n",
    "            grads = model.gradient(X_batch, y_batch)\n",
    "\n",
    "            model.params['W1'] -= learning_rate * grads['W1']\n",
    "            model.params['b1'] -= learning_rate * grads['b1']\n",
    "            model.params['exponent'] -= learning_rate * grads['exponent']\n",
    "            \n",
    "            batch_loss = model.loss(X_batch, y_batch)\n",
    "            epoch_loss += batch_loss\n",
    "            \n",
    "        avg_loss = epoch_loss / num_batches\n",
    "        history['train_loss'].append(avg_loss)\n",
    "        \n",
    "        train_acc = model.accuracy(X_train, y_train)\n",
    "        history['train_accuracy'].append(train_acc)\n",
    "        \n",
    "        if X_test is not None and y_test is not None:\n",
    "            test_loss = model.loss(X_test, y_test)\n",
    "            test_acc = model.accuracy(X_test, y_test)\n",
    "            history['test_loss'].append(test_loss)\n",
    "            history['test_accuracy'].append(test_acc)\n",
    "            \n",
    "            if verbose and (epoch + 1) % 10 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{epochs} - Loss: {avg_loss:.4f} - Test Loss: {test_loss:.4f} - Train Acc: {train_acc:.4f} - Test Acc: {test_acc:.4f}\")\n",
    "        else:\n",
    "            if verbose and (epoch + 1) % 10 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{epochs} - Loss: {avg_loss:.4f} - Train Acc: {train_acc:.4f}\")\n",
    "                \n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5db42435d4c856ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T13:07:16.977884200Z",
     "start_time": "2025-12-19T12:45:09.661720600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 1) (200, 1) (800,) (200,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = load_battery_data('BatteryData.xlsx')\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "86a5c189c0098772",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T13:07:16.977884200Z",
     "start_time": "2025-12-19T12:45:10.922845900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100 - Loss: 0.1715 - Test Loss: 0.1471 - Train Acc: 0.0000 - Test Acc: 0.0000\n",
      "Epoch 20/100 - Loss: 0.0285 - Test Loss: 0.0238 - Train Acc: 0.0312 - Test Acc: 0.0500\n",
      "Epoch 30/100 - Loss: 0.0103 - Test Loss: 0.0090 - Train Acc: 0.4800 - Test Acc: 0.4600\n",
      "Epoch 40/100 - Loss: 0.0076 - Test Loss: 0.0071 - Train Acc: 0.3950 - Test Acc: 0.3400\n",
      "Epoch 50/100 - Loss: 0.0071 - Test Loss: 0.0069 - Train Acc: 0.3525 - Test Acc: 0.3250\n",
      "Epoch 60/100 - Loss: 0.0069 - Test Loss: 0.0068 - Train Acc: 0.3250 - Test Acc: 0.3200\n",
      "Epoch 70/100 - Loss: 0.0068 - Test Loss: 0.0067 - Train Acc: 0.3250 - Test Acc: 0.3200\n",
      "Epoch 80/100 - Loss: 0.0067 - Test Loss: 0.0066 - Train Acc: 0.3412 - Test Acc: 0.3350\n",
      "Epoch 90/100 - Loss: 0.0066 - Test Loss: 0.0065 - Train Acc: 0.3412 - Test Acc: 0.3350\n",
      "Epoch 100/100 - Loss: 0.0065 - Test Loss: 0.0064 - Train Acc: 0.3412 - Test Acc: 0.3350\n"
     ]
    }
   ],
   "source": [
    "model = battery_model()\n",
    "\n",
    "history = batch_train(model, X_train, y_train, X_test, y_test,epochs=100, batch_size=100, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "619d18a2ce461fd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T13:07:16.977884200Z",
     "start_time": "2025-12-19T12:45:11.103207900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(22.568895448712816), np.float64(0.6790408526633146), np.float64(0.5586616922833635), np.float64(0.46262839494792724), np.float64(0.3848225322561779), np.float64(0.32113573089083297), np.float64(0.26864897958360073), np.float64(0.22517253261312264), np.float64(0.18902346329090497), np.float64(0.15888696408745911), np.float64(0.1337039127013272), np.float64(0.11262192138542665), np.float64(0.09494918517929249), np.float64(0.08011702182848826), np.float64(0.06765555788848308), np.float64(0.057177833222968696), np.float64(0.048361736179516786), np.float64(0.04093957013375974), np.float64(0.034686810648417984), np.float64(0.029418032853844377), np.float64(0.024976802635592057), np.float64(0.021231094766459548), np.float64(0.0180711087357286), np.float64(0.015404653537827434), np.float64(0.01315387191641959), np.float64(0.011254424169583891), np.float64(0.009649820311402385), np.float64(0.008295106584511021), np.float64(0.0071509296587408695), np.float64(0.006184132495349241), np.float64(0.005367463837977539), np.float64(0.004676868069457099), np.float64(0.004093533571364642), np.float64(0.003600829299821948), np.float64(0.0031838835145120968), np.float64(0.0028316306825163402), np.float64(0.0025338739474482564), np.float64(0.002281993444782516), np.float64(0.0020689461781453365), np.float64(0.0018887517664084327), np.float64(0.0017363406199057186), np.float64(0.0016075288918957905), np.float64(0.001498580978949772), np.float64(0.0014063834856509433), np.float64(0.0013283126112264717), np.float64(0.0012623230653878146), np.float64(0.0012062562855188238), np.float64(0.0011588099751515377), np.float64(0.0011186080141821122), np.float64(0.0010845615081189336), np.float64(0.0010557701544025302), np.float64(0.0010313191491256406), np.float64(0.0010105669877315147), np.float64(0.0009930203617905078), np.float64(0.0009780733958517573), np.float64(0.0009652201387676527), np.float64(0.0009545732708541163), np.float64(0.0009453911528587292), np.float64(0.0009375123970155478), np.float64(0.0009308185462984784), np.float64(0.0009251036134076075), np.float64(0.000920223617421724), np.float64(0.0009159967098054268), np.float64(0.0009123059784608555), np.float64(0.0009092694044840408), np.float64(0.0009065581026716004), np.float64(0.0009041904782870673), np.float64(0.0009021754715652166), np.float64(0.0009003686670486698), np.float64(0.0008987875538347336), np.float64(0.0008974149092905117), np.float64(0.0008961667954070714), np.float64(0.0008950424012078534), np.float64(0.0008940279500782089), np.float64(0.0008930609452457911), np.float64(0.0008922611754247845), np.float64(0.0008915504446179768), np.float64(0.0008908067686754959), np.float64(0.0008900763772457872), np.float64(0.0008895187809087421), np.float64(0.000888936714676661), np.float64(0.0008883513559886881), np.float64(0.0008877928065443942), np.float64(0.0008873863352558139), np.float64(0.0008867848145846926), np.float64(0.0008863694875560576), np.float64(0.0008859666922017525), np.float64(0.0008853519163610184), np.float64(0.0008849684177059599), np.float64(0.0008846218574141234), np.float64(0.0008841838312367153), np.float64(0.0008837381275324166), np.float64(0.0008833249559089119), np.float64(0.0008829538420564685), np.float64(0.0008824401384767146), np.float64(0.0008820590474463527), np.float64(0.0008816921314148259), np.float64(0.0008813080854890694), np.float64(0.0008808328280050979), np.float64(0.0008803912744314514)]\n",
      "[np.float64(0.7572862798849019), np.float64(0.6199968096585987), np.float64(0.5117384506736928), np.float64(0.42466867173516737), np.float64(0.3537469442013405), np.float64(0.2954957689642865), np.float64(0.24737525210465003), np.float64(0.20743772389433687), np.float64(0.1741971196251785), np.float64(0.14645649687220616), np.float64(0.12325696838243407), np.float64(0.10382715375104286), np.float64(0.08753428334037547), np.float64(0.07385487326832385), np.float64(0.062361296076506686), np.float64(0.052695540776149574), np.float64(0.04456423157487904), np.float64(0.03771783323223585), np.float64(0.03195114857488407), np.float64(0.027093866375203078), np.float64(0.02299981667057004), np.float64(0.01954771896364378), np.float64(0.016637062960674354), np.float64(0.014181444279897013), np.float64(0.012110514422870018), np.float64(0.010362892788222588), np.float64(0.00888771279699864), np.float64(0.0076432289999093465), np.float64(0.006593052328007252), np.float64(0.005706226901136756), np.float64(0.0049576977936434995), np.float64(0.0043252880110591805), np.float64(0.003792288335668869), np.float64(0.003341973712465301), np.float64(0.002961673149124423), np.float64(0.002640940118073545), np.float64(0.002370065282261167), np.float64(0.0021413573123404174), np.float64(0.001948329757855862), np.float64(0.0017853182375277396), np.float64(0.001647958992739207), np.float64(0.0015319429425932952), np.float64(0.0014340558138838987), np.float64(0.0013514840924866807), np.float64(0.0012818855002520418), np.float64(0.0012230151119739206), np.float64(0.0011733776746897084), np.float64(0.00113141766547512), np.float64(0.0010961419933441258), np.float64(0.0010663668158970006), np.float64(0.0010412285523866372), np.float64(0.0010201030329117509), np.float64(0.00100229748649085), np.float64(0.000987224604400101), np.float64(0.0009745142635206916), np.float64(0.0009637752667434835), np.float64(0.0009547453093954081), np.float64(0.0009470812413724225), np.float64(0.0009406077987794011), np.float64(0.0009351779563488897), np.float64(0.0009305502293584404), np.float64(0.0009266205418020958), np.float64(0.0009232890868133735), np.float64(0.0009204742054798399), np.float64(0.0009180533516078168), np.float64(0.0009159851888549911), np.float64(0.0009142152249215293), np.float64(0.0009126751288413548), np.float64(0.0009113275598472939), np.float64(0.0009101547812027684), np.float64(0.000909136203127989), np.float64(0.0009082329174987301), np.float64(0.0009074295927803894), np.float64(0.0009066999409887218), np.float64(0.0009060370055831691), np.float64(0.0009054287408191247), np.float64(0.0009048739453891366), np.float64(0.0009043516106793391), np.float64(0.0009038617435959395), np.float64(0.0009033994900414081), np.float64(0.0009029560754830379), np.float64(0.0009025288476072956), np.float64(0.0009021133732664444), np.float64(0.0009017080057374269), np.float64(0.000901311346775796), np.float64(0.0009009198263987011), np.float64(0.0009005335951870226), np.float64(0.0009001538018314248), np.float64(0.0008997727988185709), np.float64(0.000899396002699547), np.float64(0.000899019274756304), np.float64(0.0008986421569727604), np.float64(0.0008982649160603136), np.float64(0.0008978907290234242), np.float64(0.0008975171867781384), np.float64(0.0008971420887103567), np.float64(0.0008967651299984081), np.float64(0.0008963854536458279), np.float64(0.0008960082446489506), np.float64(0.0008956219051270953)]\n"
     ]
    }
   ],
   "source": [
    "print(history['train_loss'])\n",
    "print(history['test_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c448e5ffc30b5ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T13:07:16.978883100Z",
     "start_time": "2025-12-19T12:45:11.720047200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
