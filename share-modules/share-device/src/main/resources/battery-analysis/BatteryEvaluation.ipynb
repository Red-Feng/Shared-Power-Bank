{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "警告: sklearn 导入失败 (The `scipy` install you are using seems to be broken, (extension modules cannot be imported), please try reinstalling.)，将使用手动实现的 train_test_split\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "# 尝试导入 sklearn，如果失败则使用手动实现\n",
    "try:\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    USE_SKLEARN = True\n",
    "except ImportError as e:\n",
    "    print(f\"警告: sklearn 导入失败 ({e})，将使用手动实现的 train_test_split\")\n",
    "    USE_SKLEARN = False\n",
    "    \n",
    "    def train_test_split(X, y, test_size=0.2, random_state=None):\n",
    "        \"\"\"手动实现的 train_test_split，不依赖 sklearn\"\"\"\n",
    "        if random_state is not None:\n",
    "            np.random.seed(random_state)\n",
    "        \n",
    "        n_samples = len(X)\n",
    "        n_test = int(n_samples * test_size)\n",
    "        indices = np.random.permutation(n_samples)\n",
    "        \n",
    "        test_indices = indices[:n_test]\n",
    "        train_indices = indices[n_test:]\n",
    "        \n",
    "        X_train, X_test = X[train_indices], X[test_indices]\n",
    "        y_train, y_test = y[train_indices], y[test_indices]\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "def extract_numeric_features(data):\n",
    "    feature_columns = ['充放电次数', '环境温度', '当前电量']\n",
    "    numeric_data = pd.DataFrame()\n",
    "\n",
    "    for col in feature_columns:\n",
    "        if col in data.columns:\n",
    "            extracted_values = []\n",
    "            for value in data[col]:\n",
    "                if pd.isna(value):\n",
    "                    extracted_values.append(np.nan)\n",
    "                else:\n",
    "                    matches = re.findall(r'\\d+\\.?\\d*', str(value))\n",
    "                    if matches:\n",
    "                        try:\n",
    "                            extracted_values.append(float(matches[0]))\n",
    "                        except ValueError:\n",
    "                            extracted_values.append(np.nan)\n",
    "                    else:\n",
    "                        extracted_values.append(np.nan)\n",
    "            numeric_data[col] = extracted_values\n",
    "    return numeric_data\n",
    "\n",
    "\n",
    "def load_battery_data(file_path, test_ratio=0.2, random_state=None):\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"Excel文件 {file_path} 不存在\")\n",
    "\n",
    "    try:\n",
    "        data = pd.read_excel(file_path)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"读取Excel文件失败: {str(e)}\")\n",
    "\n",
    "\n",
    "    numeric_features = extract_numeric_features(data)\n",
    "\n",
    "    label_column = '电池量'\n",
    "    y = data[label_column].values\n",
    "\n",
    "    X = numeric_features.values\n",
    "    \n",
    "    # 使用已导入的 train_test_split（可能是 sklearn 或手动实现）\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_ratio, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b042f7064c9ff03",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4425c8d77ca4aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T13:07:16.975882600Z",
     "start_time": "2025-12-19T12:45:09.640782800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1192f1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "class Affine:\n",
    "    def __init__(self,W,b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.x = None\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "    \n",
    "    def forward(self,x):\n",
    "        self.x = x\n",
    "        out = np.dot(x,self.W) + self.b\n",
    "        return out\n",
    "    \n",
    "    def backward(self,dout):\n",
    "        dx = np.dot(dout,self.W.T)\n",
    "        self.dW = np.dot(self.x.T,dout)\n",
    "        self.db = np.sum(dout,axis=0)\n",
    "        return dx\n",
    "    \n",
    "class AddPower:\n",
    "    def __init__(self,exponent):\n",
    "        self.exponent = exponent\n",
    "        self.x = None\n",
    "        self.dExponent = None\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x += 1e-7\n",
    "        self.x = x\n",
    "        out = np.power(x,self.exponent)\n",
    "        return out\n",
    "    \n",
    "    def backward(self,dout):\n",
    "        dx = np.power(self.x,self.exponent-1) * self.exponent * dout\n",
    "        dExponent_full = self.x ** self.exponent * np.log(self.x) * dout\n",
    "        self.dExponent = np.sum(dExponent_full, axis=0)\n",
    "        return dx\n",
    "\n",
    "def mse(y,t):\n",
    "    return np.mean((y-t)**2) * 0.5\n",
    "\n",
    "class MSE:\n",
    "    def __init__(self):\n",
    "        self.loss = None\n",
    "        self.y = None\n",
    "        self.t = None\n",
    "    \n",
    "    def forward(self,y,t):\n",
    "        self.y = y\n",
    "        self.t = t\n",
    "        self.loss = mse(y,t)\n",
    "        return self.loss\n",
    "    \n",
    "    def backward(self,dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        if len(self.t.shape) == 1:\n",
    "            t_reshaped = self.t.reshape(-1, 1)\n",
    "        else:\n",
    "            t_reshaped = self.t\n",
    "        dx = (self.y - t_reshaped) / batch_size\n",
    "        return dx\n",
    "\n",
    "class battery_model:\n",
    "    def __init__(self,input_size=3,output_size=1,weight_init=0.1):\n",
    "        self.params = {}\n",
    "        self.params['exponent'] = np.ones(input_size)\n",
    "        self.params['W1'] = np.random.randn(input_size,output_size) * weight_init\n",
    "        self.params['b1'] = np.zeros(output_size)\n",
    "        \n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['AddPower'] = AddPower(self.params['exponent'])\n",
    "        self.layers['Affine1'] = Affine(self.params['W1'], self.params['b1'])\n",
    "        \n",
    "        self.loss_layer = MSE()\n",
    "        \n",
    "        \n",
    "    def predict(self,x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "    \n",
    "    def loss(self,x,t):\n",
    "        y = self.predict(x)\n",
    "        if len(t.shape) == 1:\n",
    "            t = t.reshape(-1, 1)\n",
    "        return self.loss_layer.forward(y,t)\n",
    "    \n",
    "    def gradient(self,x,t):\n",
    "        if len(t.shape) == 1:\n",
    "            t = t.reshape(-1, 1)\n",
    "        self.loss(x,t)\n",
    "        dout = self.loss_layer.backward()\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "        \n",
    "        gradient = {\n",
    "                'exponent': self.layers['AddPower'].dExponent,\n",
    "                'W1': self.layers['Affine1'].dW,\n",
    "                'b1': self.layers['Affine1'].db\n",
    "        }\n",
    "        \n",
    "        return gradient\n",
    "    \n",
    "    def accuracy(self,x,t,threshold=0.05):\n",
    "        y = self.predict(x)\n",
    "        \n",
    "        if len(t.shape) == 1:\n",
    "            t = t.reshape(-1, 1)\n",
    "\n",
    "        relative_error = np.abs((y - t) / (t + 1e-7))\n",
    "\n",
    "        correct = relative_error <= threshold\n",
    "        return np.mean(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f74b7f93dad23896",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T13:07:16.976882900Z",
     "start_time": "2025-12-19T12:45:09.648105100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def batch_train(model, X_train, y_train, X_test=None, y_test=None, epochs=10, batch_size=100, learning_rate=0.01, verbose=True):\n",
    "\n",
    "    num_samples = X_train.shape[0]\n",
    "    num_batches = num_samples // batch_size\n",
    "    \n",
    "    if num_samples % batch_size != 0:\n",
    "        num_batches += 1\n",
    "        \n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'test_loss': [],\n",
    "        'train_accuracy': [],\n",
    "        'test_accuracy': []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        indices = np.random.permutation(num_samples)\n",
    "        X_train_shuffled = X_train[indices]\n",
    "        y_train_shuffled = y_train[indices]\n",
    "        \n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for i in range(num_batches):\n",
    "            start_idx = i * batch_size\n",
    "            end_idx = min((i + 1) * batch_size, num_samples)\n",
    "            \n",
    "            X_batch = X_train_shuffled[start_idx:end_idx]\n",
    "            y_batch = y_train_shuffled[start_idx:end_idx]\n",
    "            \n",
    "            grads = model.gradient(X_batch, y_batch)\n",
    "\n",
    "            model.params['W1'] -= learning_rate * grads['W1']\n",
    "            model.params['b1'] -= learning_rate * grads['b1']\n",
    "            model.params['exponent'] -= learning_rate * grads['exponent']\n",
    "            \n",
    "            batch_loss = model.loss(X_batch, y_batch)\n",
    "            epoch_loss += batch_loss\n",
    "            \n",
    "        avg_loss = epoch_loss / num_batches\n",
    "        history['train_loss'].append(avg_loss)\n",
    "        \n",
    "        train_acc = model.accuracy(X_train, y_train)\n",
    "        history['train_accuracy'].append(train_acc)\n",
    "        \n",
    "        if X_test is not None and y_test is not None:\n",
    "            test_loss = model.loss(X_test, y_test)\n",
    "            test_acc = model.accuracy(X_test, y_test)\n",
    "            history['test_loss'].append(test_loss)\n",
    "            history['test_accuracy'].append(test_acc)\n",
    "            \n",
    "            if verbose and (epoch + 1) % 10 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{epochs} - Loss: {avg_loss:.4f} - Test Loss: {test_loss:.4f} - Train Acc: {train_acc:.4f} - Test Acc: {test_acc:.4f}\")\n",
    "        else:\n",
    "            if verbose and (epoch + 1) % 10 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{epochs} - Loss: {avg_loss:.4f} - Train Acc: {train_acc:.4f}\")\n",
    "                \n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5db42435d4c856ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T13:07:16.977884200Z",
     "start_time": "2025-12-19T12:45:09.661720600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 1) (200, 1) (800,) (200,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = load_battery_data('BatteryData.xlsx')\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86a5c189c0098772",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T13:07:16.977884200Z",
     "start_time": "2025-12-19T12:45:10.922845900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100 - Loss: 0.1921 - Test Loss: 0.1807 - Train Acc: 0.0000 - Test Acc: 0.0000\n",
      "Epoch 20/100 - Loss: 0.0342 - Test Loss: 0.0346 - Train Acc: 0.0037 - Test Acc: 0.0150\n",
      "Epoch 30/100 - Loss: 0.0123 - Test Loss: 0.0137 - Train Acc: 0.4988 - Test Acc: 0.4500\n",
      "Epoch 40/100 - Loss: 0.0088 - Test Loss: 0.0102 - Train Acc: 0.3837 - Test Acc: 0.3850\n",
      "Epoch 50/100 - Loss: 0.0082 - Test Loss: 0.0094 - Train Acc: 0.3463 - Test Acc: 0.3500\n",
      "Epoch 60/100 - Loss: 0.0079 - Test Loss: 0.0091 - Train Acc: 0.3175 - Test Acc: 0.3500\n",
      "Epoch 70/100 - Loss: 0.0078 - Test Loss: 0.0089 - Train Acc: 0.2988 - Test Acc: 0.3400\n",
      "Epoch 80/100 - Loss: 0.0077 - Test Loss: 0.0088 - Train Acc: 0.2988 - Test Acc: 0.3400\n",
      "Epoch 90/100 - Loss: 0.0075 - Test Loss: 0.0086 - Train Acc: 0.2988 - Test Acc: 0.3400\n",
      "Epoch 100/100 - Loss: 0.0074 - Test Loss: 0.0085 - Train Acc: 0.2988 - Test Acc: 0.3400\n"
     ]
    }
   ],
   "source": [
    "model = battery_model()\n",
    "\n",
    "history = batch_train(model, X_train, y_train, X_test, y_test,epochs=100, batch_size=100, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "619d18a2ce461fd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T13:07:16.977884200Z",
     "start_time": "2025-12-19T12:45:11.103207900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(10.407056124008024), np.float64(1.3477983923614962), np.float64(0.9676237487175472), np.float64(0.7303682016117576), np.float64(0.5667221023273304), np.float64(0.447583946551082), np.float64(0.3579183338306613), np.float64(0.28883801651042157), np.float64(0.2348150846272925), np.float64(0.1920856644014456), np.float64(0.15798178443832367), np.float64(0.13059503306468576), np.float64(0.10847299323003273), np.float64(0.09052173166784841), np.float64(0.07591477365467462), np.float64(0.06399405463719894), np.float64(0.0542343808222541), np.float64(0.04622767403707588), np.float64(0.03964975803696969), np.float64(0.034234141910816945), np.float64(0.029772515579354758), np.float64(0.02608935082159409), np.float64(0.0230434600368923), np.float64(0.020530330973464708), np.float64(0.01844731921002157), np.float64(0.016724986095645503), np.float64(0.015290958159207235), np.float64(0.014102364797585126), np.float64(0.013116694818168462), np.float64(0.012295177506630993), np.float64(0.011611086935576956), np.float64(0.01104078739288648), np.float64(0.010564425626717158), np.float64(0.010167000432750366), np.float64(0.009834802309070752), np.float64(0.009557477925250801), np.float64(0.009323692931079548), np.float64(0.009127352272111675), np.float64(0.008961221245923245), np.float64(0.008821096449720053), np.float64(0.008701200791748692), np.float64(0.008601141256312082), np.float64(0.008513969341618915), np.float64(0.00843941908969278), np.float64(0.008373890303720672), np.float64(0.00831751147809978), np.float64(0.008269158386243626), np.float64(0.008226545073821213), np.float64(0.008189232113364264), np.float64(0.008154955259296737), np.float64(0.008124298980016684), np.float64(0.008095713570240954), np.float64(0.008070396025541876), np.float64(0.00804751917595904), np.float64(0.008026382682721217), np.float64(0.008005548992147745), np.float64(0.007985939330449627), np.float64(0.007967404733506496), np.float64(0.007951132645544806), np.float64(0.007933982369508664), np.float64(0.007917480648851423), np.float64(0.007902659135832244), np.float64(0.007887054075301264), np.float64(0.007871359701965806), np.float64(0.007857277821093906), np.float64(0.007842126425001976), np.float64(0.007828735162478992), np.float64(0.007814813792729655), np.float64(0.007800922320631122), np.float64(0.0077869888876929095), np.float64(0.0077734448155150696), np.float64(0.007759957090066668), np.float64(0.0077463100100864605), np.float64(0.007733179061697401), np.float64(0.00772029429412216), np.float64(0.0077069925107004274), np.float64(0.007693327264399271), np.float64(0.00768092489151219), np.float64(0.0076669333614339565), np.float64(0.007655662034632982), np.float64(0.0076425820536719586), np.float64(0.0076299888319604214), np.float64(0.007616951846535815), np.float64(0.007604549784804573), np.float64(0.007591767912799803), np.float64(0.00757861168778795), np.float64(0.007566403698999633), np.float64(0.007553891468026058), np.float64(0.00754102784525025), np.float64(0.0075292341746046425), np.float64(0.00751622923030469), np.float64(0.007503839486470731), np.float64(0.007491586171943372), np.float64(0.007479377992957894), np.float64(0.007465342542891664), np.float64(0.007454849338673725), np.float64(0.007442368663961342), np.float64(0.007430363803301865), np.float64(0.007417786952594023), np.float64(0.007405344971710982)]\n",
      "[np.float64(1.6837951711991272), np.float64(1.15970621307713), np.float64(0.8582122119900402), np.float64(0.6586010555536853), np.float64(0.5166282871574276), np.float64(0.41140025115917006), np.float64(0.3311304601546864), np.float64(0.26877315312909056), np.float64(0.21970855840363002), np.float64(0.1806761335622933), np.float64(0.14939984052047614), np.float64(0.12419905061977474), np.float64(0.10375875516704738), np.float64(0.08713599713124756), np.float64(0.07357591152424088), np.float64(0.06247267283333288), np.float64(0.05335957457823325), np.float64(0.045864901453280975), np.float64(0.03969347497429077), np.float64(0.034595642242548), np.float64(0.030385713145424344), np.float64(0.02689652611359302), np.float64(0.02400598057370797), np.float64(0.021608709937033326), np.float64(0.019620476748310765), np.float64(0.017961067603783767), np.float64(0.01657935319119572), np.float64(0.015428684546397585), np.float64(0.014466701868195535), np.float64(0.01366185721469477), np.float64(0.012987815792878226), np.float64(0.01242193832741596), np.float64(0.011946933657131613), np.float64(0.011547201243644691), np.float64(0.01121119926204559), np.float64(0.01092592450140225), np.float64(0.0106851107027511), np.float64(0.010480008985214555), np.float64(0.01030513766755707), np.float64(0.01015494516857488), np.float64(0.010027090841219298), np.float64(0.009915923300838177), np.float64(0.009819544444464933), np.float64(0.0097357926439686), np.float64(0.009662230150533451), np.float64(0.009597710392973004), np.float64(0.009540531222692524), np.float64(0.009490112627860585), np.float64(0.009444495074060312), np.float64(0.009403345772420428), np.float64(0.009365952329959243), np.float64(0.00933195705230442), np.float64(0.009300099638356606), np.float64(0.00927103447527275), np.float64(0.009243863683075544), np.float64(0.009218153223905233), np.float64(0.009194065714388834), np.float64(0.009171132388619467), np.float64(0.009149230641347789), np.float64(0.009128163399543981), np.float64(0.009107944068662105), np.float64(0.009088350410781064), np.float64(0.009069203394043908), np.float64(0.009050662992224142), np.float64(0.009032688688452988), np.float64(0.009015012190447822), np.float64(0.008997656686318274), np.float64(0.008980727956244614), np.float64(0.008964053876165792), np.float64(0.008947375618015896), np.float64(0.008931007243677068), np.float64(0.008914816739749977), np.float64(0.00889875997839186), np.float64(0.008882946573660466), np.float64(0.008867311303543563), np.float64(0.008851875382796229), np.float64(0.00883656139124979), np.float64(0.008821228875726997), np.float64(0.008806212545713246), np.float64(0.008791214303334802), np.float64(0.008776183427291013), np.float64(0.00876128302001161), np.float64(0.008746533629738805), np.float64(0.008731765289447503), np.float64(0.008717180416020862), np.float64(0.008702647530917321), np.float64(0.00868814384576979), np.float64(0.008673623098553896), np.float64(0.008659191131597731), np.float64(0.008644774071644434), np.float64(0.008630462360079106), np.float64(0.008616112710122756), np.float64(0.008601869710812518), np.float64(0.008587774292090145), np.float64(0.008573749034475586), np.float64(0.00855969353772352), np.float64(0.008545631105424287), np.float64(0.00853172568866333), np.float64(0.008517846048076656), np.float64(0.008504006984267813)]\n"
     ]
    }
   ],
   "source": [
    "print(history['train_loss'])\n",
    "print(history['test_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c448e5ffc30b5ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T13:07:16.978883100Z",
     "start_time": "2025-12-19T12:45:11.720047200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
